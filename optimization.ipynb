{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/5ZtWoHcgPxfYbvstzOQY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Model Parameters"
      ],
      "metadata": {
        "id": "YF4U6-AmKVie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "pETdkGAZKbra"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0JPL55boKQOj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prerequiste code"
      ],
      "metadata": {
        "id": "Qa1cvuNwLPAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\" if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"device: {device}\")\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw5-71w1LR7U",
        "outputId": "d9fac451-0985-4b03-89fc-260e9a512728"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "u0fCsZMHO-Fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "hC4F8C-_O_bL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function"
      ],
      "metadata": {
        "id": "tTEsYSA0PJ6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ewT14SNoPNQX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizer"
      ],
      "metadata": {
        "id": "QeXT9QH_RyiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "0n7Lm_4lRUYp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full Implementation"
      ],
      "metadata": {
        "id": "GTUAtO-nSXAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    # Compute the prediction and loss\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Perform backprop\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:7f} [{current:>5d}/{size:5d}]\")"
      ],
      "metadata": {
        "id": "D4r_XP8hS7tA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n Accuracy {100 * correct:>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "ncB0-H8zV49v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch: {t+1}\\n---------------------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  test_loop(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbThuwGgW_wK",
        "outputId": "ee7c7e3b-b06e-4594-eaa1-3cfd9232b6be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "---------------------------------\n",
            "loss: 2.291566 [   64/60000]\n",
            "loss: 2.283365 [ 6464/60000]\n",
            "loss: 2.263372 [12864/60000]\n",
            "loss: 2.265101 [19264/60000]\n",
            "loss: 2.243771 [25664/60000]\n",
            "loss: 2.213560 [32064/60000]\n",
            "loss: 2.230381 [38464/60000]\n",
            "loss: 2.189734 [44864/60000]\n",
            "loss: 2.185502 [51264/60000]\n",
            "loss: 2.162635 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 37.7%, Avg loss: 2.151333 \n",
            "\n",
            "Epoch: 2\n",
            "---------------------------------\n",
            "loss: 2.155950 [   64/60000]\n",
            "loss: 2.145490 [ 6464/60000]\n",
            "loss: 2.088720 [12864/60000]\n",
            "loss: 2.114532 [19264/60000]\n",
            "loss: 2.065638 [25664/60000]\n",
            "loss: 1.998651 [32064/60000]\n",
            "loss: 2.038881 [38464/60000]\n",
            "loss: 1.953502 [44864/60000]\n",
            "loss: 1.966091 [51264/60000]\n",
            "loss: 1.903831 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 54.6%, Avg loss: 1.891538 \n",
            "\n",
            "Epoch: 3\n",
            "---------------------------------\n",
            "loss: 1.917212 [   64/60000]\n",
            "loss: 1.886294 [ 6464/60000]\n",
            "loss: 1.772053 [12864/60000]\n",
            "loss: 1.826260 [19264/60000]\n",
            "loss: 1.720037 [25664/60000]\n",
            "loss: 1.660085 [32064/60000]\n",
            "loss: 1.694009 [38464/60000]\n",
            "loss: 1.585568 [44864/60000]\n",
            "loss: 1.622015 [51264/60000]\n",
            "loss: 1.525899 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 63.0%, Avg loss: 1.531421 \n",
            "\n",
            "Epoch: 4\n",
            "---------------------------------\n",
            "loss: 1.593525 [   64/60000]\n",
            "loss: 1.554465 [ 6464/60000]\n",
            "loss: 1.406107 [12864/60000]\n",
            "loss: 1.487728 [19264/60000]\n",
            "loss: 1.373065 [25664/60000]\n",
            "loss: 1.357759 [32064/60000]\n",
            "loss: 1.374582 [38464/60000]\n",
            "loss: 1.295856 [44864/60000]\n",
            "loss: 1.340413 [51264/60000]\n",
            "loss: 1.243568 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 64.2%, Avg loss: 1.263270 \n",
            "\n",
            "Epoch: 5\n",
            "---------------------------------\n",
            "loss: 1.342207 [   64/60000]\n",
            "loss: 1.315705 [ 6464/60000]\n",
            "loss: 1.152403 [12864/60000]\n",
            "loss: 1.260041 [19264/60000]\n",
            "loss: 1.143171 [25664/60000]\n",
            "loss: 1.159868 [32064/60000]\n",
            "loss: 1.173920 [38464/60000]\n",
            "loss: 1.114541 [44864/60000]\n",
            "loss: 1.161555 [51264/60000]\n",
            "loss: 1.079113 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 65.4%, Avg loss: 1.094587 \n",
            "\n",
            "Epoch: 6\n",
            "---------------------------------\n",
            "loss: 1.170314 [   64/60000]\n",
            "loss: 1.162814 [ 6464/60000]\n",
            "loss: 0.983750 [12864/60000]\n",
            "loss: 1.116359 [19264/60000]\n",
            "loss: 1.000301 [25664/60000]\n",
            "loss: 1.025019 [32064/60000]\n",
            "loss: 1.048957 [38464/60000]\n",
            "loss: 0.997124 [44864/60000]\n",
            "loss: 1.044892 [51264/60000]\n",
            "loss: 0.977207 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 66.6%, Avg loss: 0.985019 \n",
            "\n",
            "Epoch: 7\n",
            "---------------------------------\n",
            "loss: 1.049524 [   64/60000]\n",
            "loss: 1.062797 [ 6464/60000]\n",
            "loss: 0.866641 [12864/60000]\n",
            "loss: 1.021007 [19264/60000]\n",
            "loss: 0.909788 [25664/60000]\n",
            "loss: 0.928933 [32064/60000]\n",
            "loss: 0.966628 [38464/60000]\n",
            "loss: 0.919574 [44864/60000]\n",
            "loss: 0.964601 [51264/60000]\n",
            "loss: 0.909288 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 67.8%, Avg loss: 0.910286 \n",
            "\n",
            "Epoch: 8\n",
            "---------------------------------\n",
            "loss: 0.960633 [   64/60000]\n",
            "loss: 0.993176 [ 6464/60000]\n",
            "loss: 0.782401 [12864/60000]\n",
            "loss: 0.954338 [19264/60000]\n",
            "loss: 0.848718 [25664/60000]\n",
            "loss: 0.858491 [32064/60000]\n",
            "loss: 0.908693 [38464/60000]\n",
            "loss: 0.867245 [44864/60000]\n",
            "loss: 0.907302 [51264/60000]\n",
            "loss: 0.860540 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 68.8%, Avg loss: 0.856687 \n",
            "\n",
            "Epoch: 9\n",
            "---------------------------------\n",
            "loss: 0.892176 [   64/60000]\n",
            "loss: 0.940989 [ 6464/60000]\n",
            "loss: 0.719423 [12864/60000]\n",
            "loss: 0.905183 [19264/60000]\n",
            "loss: 0.804676 [25664/60000]\n",
            "loss: 0.805800 [32064/60000]\n",
            "loss: 0.864656 [38464/60000]\n",
            "loss: 0.830457 [44864/60000]\n",
            "loss: 0.864797 [51264/60000]\n",
            "loss: 0.823322 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 70.1%, Avg loss: 0.816286 \n",
            "\n",
            "Epoch: 10\n",
            "---------------------------------\n",
            "loss: 0.837744 [   64/60000]\n",
            "loss: 0.899140 [ 6464/60000]\n",
            "loss: 0.670578 [12864/60000]\n",
            "loss: 0.867584 [19264/60000]\n",
            "loss: 0.770989 [25664/60000]\n",
            "loss: 0.765725 [32064/60000]\n",
            "loss: 0.829121 [38464/60000]\n",
            "loss: 0.803201 [44864/60000]\n",
            "loss: 0.831830 [51264/60000]\n",
            "loss: 0.793569 [57664/60000]\n",
            "Test Error: \n",
            " Accuracy 71.5%, Avg loss: 0.784348 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    }
  ]
}